{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Evaluate Random Forest with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid-search:** Exhaustively search all parameter combinations in a given grid to determine the best model.\n",
    "\n",
    "**Cross-validation:** Divide a dataset into k subsets and repeat the holdout method k times where a different subset is used as the holdout set in each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  0  1  2  3  4  5  6  7  ...  8094  8095  8096  8097   \n",
       "0       128     4.7  0  0  0  0  0  0  0  0  ...     0     0     0     0  \\\n",
       "1        49     4.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "2        62     3.2  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "3        28     7.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "4       135     4.4  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "\n",
       "   8098  8099  8100  8101  8102  8103  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "\n",
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_feat.columns = X_tfidf_feat.columns.astype(str)\n",
    "X_count_feat.columns = X_count_feat.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring parameter settings using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [150, 300],\n",
    "        'max_depth': [60, 90]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "11 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\generic.py\", line 1997, in __array__\n",
      "    values = self._values\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\", line 1000, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\", line 11360, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1732, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1768, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 275. MiB for an array with shape (8106, 4453) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\generic.py\", line 1997, in __array__\n",
      "    values = self._values\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\", line 1000, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\", line 11360, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1732, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1768, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 275. MiB for an array with shape (8106, 4454) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\sachi\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.97053978]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.146480</td>\n",
       "      <td>3.767449</td>\n",
       "      <td>0.173946</td>\n",
       "      <td>0.019489</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.97054</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.782796</td>\n",
       "      <td>1.171064</td>\n",
       "      <td>0.119055</td>\n",
       "      <td>0.238111</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 10}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.957772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.852177</td>\n",
       "      <td>3.406579</td>\n",
       "      <td>0.043976</td>\n",
       "      <td>0.087953</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 150}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.322964</td>\n",
       "      <td>1.480604</td>\n",
       "      <td>0.221681</td>\n",
       "      <td>0.271715</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time   \n",
       "3      15.146480      3.767449         0.173946        0.019489  \\\n",
       "0      10.782796      1.171064         0.119055        0.238111   \n",
       "1      11.852177      3.406579         0.043976        0.087953   \n",
       "2      11.322964      1.480604         0.221681        0.271715   \n",
       "\n",
       "  param_max_depth param_n_estimators                                  params   \n",
       "3              60                150  {'max_depth': 60, 'n_estimators': 150}  \\\n",
       "0              30                 10   {'max_depth': 30, 'n_estimators': 10}   \n",
       "1              30                150  {'max_depth': 30, 'n_estimators': 150}   \n",
       "2              60                 10   {'max_depth': 60, 'n_estimators': 10}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score   \n",
       "3           0.975763           0.970377           0.972147           0.966757  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN           0.963163                NaN   \n",
       "2                NaN           0.973968                NaN           0.959569   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "3           0.967655          0.97054        0.003241                1  \n",
       "0           0.957772              NaN             NaN                2  \n",
       "1                NaN              NaN             NaN                2  \n",
       "2                NaN              NaN             NaN                2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
